# coding: utf-8
# Copyright (c) Pymatgen Development Team.
# Distributed under the terms of the MIT License.

from __future__ import division, print_function, unicode_literals, absolute_import

"""
This module implements classes for processing Lammps output files:

    1. log file: contains the thermodynamic data with the format set by the
        'thermo_style' command

    2. trajectory file(dump file): the file generated by the 'dump' command

    Restrictions:
        The first 2 fields of the ATOMS section in the trajectory(dump) file
        must be the atom id and the atom type. There can be arbitrary number
        of fields after that and they all will be treated as floats and
        updated based on the field names in the ITEM: ATOMS line.
"""

import re
import glob
from io import StringIO

import numpy as np
import pandas as pd

# from monty.json import MSONable
from monty.io import zopen

from pymatgen.io.lammps.data import LammpsBox

__author__ = "Kiran Mathew"
__email__ = "kmathew@lbl.gov"
__credits__ = "Navnidhi Rajput, Michael Humbert"


class LammpsLog(object):
    """
    Log file parser with focus on thermo data. Both one and multi line
    formats are supported.

    Notes:
        SHAKE stats printed with thermo data are not supported yet.
        They are ignored in multi line format, while they may cause
        issues with dataframe parsing in one line format.

    Attributes:
        runs ([pd.DataFrame]): Thermo data in a DataFrame for each run.

    """

    def __init__(self, filename="log.lammps"):
        """
        Args:
            filename (str): Filename to parse.

        """
        self.filename = filename
        with open(self.filename) as f:
            lines = f.readlines()
        begin_flag = ("Memory usage per processor =",
                      "Per MPI rank memory allocation (min/avg/max) =")
        end_flag = "Loop time of"
        begins, ends = [], []
        for i, l in enumerate(lines):
            if l.startswith(begin_flag):
                begins.append(i)
            elif l.startswith(end_flag):
                ends.append(i)

        self.runs =[]
        for b, e in zip(begins, ends):
            self.runs.append(self._parse(lines[b + 1:e]))

    @staticmethod
    def _parse(lines):
        multi_pattern = r"-+\s+Step\s+([0-9]+)\s+-+"
        # multi line thermo data
        if re.match(multi_pattern, lines[0]):
            timestep_marks = [i for i, l in enumerate(lines)
                              if re.match(multi_pattern, l)]
            timesteps = np.split(lines, timestep_marks)[1:]
            dicts = []
            kv_pattern = r"([0-9A-Za-z_\[\]]+)\s+=\s+([0-9eE\.+-]+)"
            for ts in timesteps:
                data = {}
                data["Step"] = int(re.match(multi_pattern, ts[0]).group(1))
                data.update({k: float(v) for k, v
                             in re.findall(kv_pattern, "".join(ts[1:]))})
                dicts.append(data)
            df = pd.DataFrame(dicts)
            # rearrange the sequence of columns
            columns = ["Step"] + [k for k, v in
                                  re.findall(kv_pattern,
                                             "".join(timesteps[0][1:]))]
            df = df[columns]
        # one line thermo data
        else:
            df = pd.read_csv(StringIO("".join(lines)), delim_whitespace=True)
        return df


class LammpsDump(object):
    """
    Dump file parser.

    """

    def __init__(self, filename, parse_box=True, dtype=float):
        """

        Args:
            filename (str): Filename to parse. The timestep wildcard
                ('*') is supported and the files are parsed in the
                sequence of timestep.
            parse_box (bool): Whether parse box info for each step.
                Default to True.
            dtype: np.dtype for atoms data array.

        """
        self.filename = filename
        self.parse_box = parse_box
        self.dtype = dtype

        files = glob.glob(self.filename)
        if len(files) > 1:
            pattern = r"%s" % filename.replace("*", "([0-9]+)")
            pattern = pattern.replace("\\", "\\\\")
            files = sorted(files,
                           key=lambda f: int(re.match(pattern, f).group(1)))
        self.all_files = files

    def read(self):
        """
        Generator that yields data (dict) for each timestep.

        Yields:
            {"timestep" (int): current timestep,
             "natoms" (int): no. of atoms,
             "box" (LammpsBox): simulation box (can be ignored if
                parse_box=False),
             "data" (np.array): dumped atomic data.}

        """
        for fname in self.all_files:
            with zopen(fname, "rt") as f:
                run = f.read()
            dumps = run.split("ITEM: TIMESTEP")[1:]
            for d in dumps:
                yield self._parse_timestep(d)

    def _parse_timestep(self, dump):
        step = {}
        lines = dump.split("\n")
        step["timestep"] = int(lines[1])
        step["natoms"] = int(lines[3])
        step["data"] = np.loadtxt(StringIO("\n".join(lines[9:])),
                                  dtype=self.dtype)
        if self.parse_box:
            box_arr = np.loadtxt(StringIO("\n".join(lines[5:8])))
            bounds = box_arr[:, :2]
            tilt = None
            if "xy xz yz" in lines[4]:
                tilt = box_arr[:, 2]
                x = (0, tilt[0], tilt[1], tilt[0] + tilt[1])
                y = (0, tilt[2])
                bounds -= np.array([[min(x), max(x)], [min(y), max(y)],
                                    [0, 0]])
            step["box"] = LammpsBox(bounds, tilt)
        return step
